services:
  actual-ai:
    image: docker.io/sakowicz/actual-ai:latest
    container_name: actual-ai
    restart: unless-stopped
    depends_on:
      actual-server:
        condition: service_healthy
    environment:
      ACTUAL_SERVER_URL: http://actual-server:5006
      ACTUAL_PASSWORD: ${ACTUAL_PASSWORD}
      ACTUAL_BUDGET_ID: ${ACTUAL_BUDGET_ID} # This is the ID from Settings → Show advanced settings → Sync ID
      CLASSIFICATION_SCHEDULE_CRON: 0 */4 * * *
      LLM_PROVIDER: openai # Can be "openai", "anthropic", "google-generative-ai", "ollama" or "groq"
      FEATURES: '["classifyOnStartup", "freeWebSearch", "suggestNewCategories"]'
      OPENAI_API_KEY: ${OPENAI_API_KEY} # optional. required if you want to use the OpenAI API
      # OPENAI_MODEL:  # optional. required if you want to use a specific model, default is "gpt-4o-mini"
      # OPENAI_BASE_URL:  # optional. required if you don't want to use the OpenAI API but OpenAI compatible API, ex: "http://ollama:11424/v1
      # VALUESERP_API_KEY: your_valueserp_api_key # API key for ValueSerp, required if webSearch tool is enabled
      # ANTHROPIC_API_KEY:  # optional. required if you want to use the Anthropic API
      # ANTHROPIC_MODEL:  # optional. required if you want to use a specific model, default is "claude-3-5-sonnet-latest"
      # ANTHROPIC_BASE_URL:  # optional. default: "https://api.anthropic.com/v1
      # GOOGLE_GENERATIVE_AI_API_KEY:  # optional. required if you want to use the Google Generative AI API
      # GOOGLE_GENERATIVE_AI_MODEL:  # optional. required if you want to use a specific model, default is "gemini-1.5-flash"
      # GOOGLE_GENERATIVE_AI_BASE_URL:  # optional. default: "https://generativelanguage.googleapis.com"
      # OLLAMA_MODEL=llama3.1 optional. required if you want to use an Ollama specific model, default is "phi3.5"
      # OLLAMA_BASE_URL=http://localhost:11434/api # optional. required for ollama provider
      # GROQ_API_KEY:  # optional. required if you want to use the Groq API
      # GROQ_MODEL:  # optional. required if you want to use a specific model, default is "mixtral-8x7b-32768"
      # GROQ_BASE_URL:  # optional. default: "https://api.groq.com/openai/v1"
      # ACTUAL_E2E_PASSWORD:  # optional. required if you have E2E encryption
      # NODE_TLS_REJECT_UNAUTHORIZED: 0 # optional. required if you have trouble connecting to Actual server
      # NOT_GUESSED_TAG=#actual-ai-miss
      # GUESSED_TAG=#actual-ai
    networks:
      - actual

  actual-server:
    image: docker.io/actualbudget/actual-server:latest
    container_name: actual-server
    ports:
      - "5006:5006"
    environment:
      # - ACTUAL_HTTPS_KEY=/data/selfhost.key
      # - ACTUAL_HTTPS_CERT=/data/selfhost.crt
      - ACTUAL_PORT=5006
      # - DEBUG=actual:config
      # - ACTUAL_UPLOAD_FILE_SYNC_SIZE_LIMIT_MB=20
      # - ACTUAL_UPLOAD_SYNC_ENCRYPTED_FILE_SYNC_SIZE_LIMIT_MB=50
      # - ACTUAL_UPLOAD_FILE_SIZE_LIMIT_MB=20
      # See all options and more details at https://actualbudget.github.io/docs/Installing/Configuration
    volumes:
      - actual-data:/data
    healthcheck:
      test: ["CMD-SHELL", "node src/scripts/health-check.js"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 20s
    restart: unless-stopped
    networks:
      - actual

volumes:
  actual-data:

networks:
  actual:
    driver: bridge
